---

### ðŸ§© **Milestone 1 Overview**

Milestone 1 focuses on understanding how transformer-based models interpret the semantics of Python source code using advanced NLP techniques. The process begins with collecting multiple Python snippets that represent various programming constructs. These snippets are first parsed into **Abstract Syntax Trees (ASTs)** to extract their logical structure and relationships between elements like functions, loops, and classes. Next, **tokenization** converts the code into model-readable tokens, which are then encoded into **semantic embeddings** using pretrained models â€” **MiniLM**, **DistilRoBERTa**, and **MPNet**. Each model produces numerical vectors representing the meaning of the code, and **cosine similarity** is applied to compare these embeddings against conceptual categories such as *code structure*, *algorithmic logic*, and *control flow*. The results reveal how each model focuses differently on aspects of the code: **MiniLM** excels in algorithmic reasoning, **DistilRoBERTa** in contextual understanding, and **MPNet** in structural comprehension. Finally, through **model comparison and visualization**, similarities and performance differences are analyzed using heatmaps and tables. This milestone bridges **static code analysis** with **semantic understanding**, demonstrating how embedding models can capture the deeper logic of programming, paving the way for future integration with **Large Language Models (LLMs)** for explainable AI-driven code analysis.

---
